marketing = as_tibble(marketing)
marketing
marketing
library(tidyverse)
library(datarium)
marketing = as_tibble(marketing)
marketing
ggplot(data=marketing, aes(x=youtube, y=sales)) +
geom_point()
#we want to seed the advertisement of the youtube single
ggplot(data=marketing, aes(x=youtube, y=sales)) +
geom_point()
#questions 4
x = marketing$youtube
y = marketing$sales
#Model is y= a + b*x
model = lm(y~x)
summary(model)
a = model$coefficients[1]
b = model$coefficients[2]
a
b
ggplot(marketing, aes(x=youtube, y=sales)) +
goem_point()
ggplot(marketing, aes(x=youtube, y=sales)) +
goem_point()
ggplot(marketing, aes(x=youtube, y=sales)) +
goem_point() +
goem_smooth(method=lm, se=FALSE)
ggplot(marketing, aes(x=youtube, y=sales)) +
goem_point() +
goem_smooth(method=lm, se=FALSE)
ggplot(marketing, aes(x=youtube, y=sales)) +
geom_point() +
geom_smooth(method=lm, se=FALSE)
model = lm(sales~youtube, data=marketing)
summary(model)
library(broom)
tidy(model)
fitted = argument(model)
fitted = augment(model)
fitted()
fitted = augment(model)
fitted
ggplot(fitted, aes(x=youtube, y=sales)) +
geom_point() +
geom_smooth(method=lm, se=FALSE) +
geom_segment(aes(xend=youtube, yend=.fitted), color='red', size=0.3)
library(tidyverse)
library(datarium)
marketing = as_tibble(marketing)
marketing
observed_sales = marketing$sales
observed_sales
model = lm(sales~youtube, data=marketing)
summary(model)
a
b
predicted_sales = a + b*marketing$youtube
predicted_sales
residuals_sales=observed_sales - predicted_sales
residuals_sales
ggplot(Null, aes(x=predicted_sales, y=residual_sales)) +
geom_point()
library(tidyverse)
library(datarium)
marketing = as_tibble(marketing)
marketing
observed_sales = marketing$sales
observed_sales
model = lm(sales~youtube, data=marketing)
summary(model)
a = model$coefficients[1]
b = model$coefficients[2]
a
b
predicted_sales = a + b*marketing$youtube
predicted_sales
residuals_sales=observed_sales - predicted_sales
residuals_sales
ggplot(Null, aes(x=predicted_sales, y=residual_sales)) +
geom_point()
residual_sales=observed_sales - predicted_sales
residual_sales
ggplot(Null,aes(x=predicted_sales, y=residual_sales)) +
geom_point()
ggplot(NULL,aes(x=predicted_sales, y=residual_sales)) +
geom_point()
#next way how to get the same
model = lmm(sales~youtbe, data=marketing)
model = lm(sales~youtbe, data=marketing)
model = lm(sales~youtube, data=marketing)
library(broom)
augment(model) %>%
ggplot(aes(x=.fitted, y=.resid)) +
geom_point()
ggplot(NULL,aes(x=predicted_sales, y=residual_sales)) +
geom_point()
install.packages("ggfortify")
library(ggfortify)
model = lm(sales~youtube, data=marketing)
autoplot(model)
#diagnostic plot
library(ggfortify)
model = lm(sales~youtube + facebook, data=marketing)
autoplot(model)
modelA = lm(sales~youtube, data=marketing)
summary(modelA)
modelB = lm(sales~youtube + facebook, data=marketing)
summary(modelB)
library(tidyverse)
library(ISLR)
credit = as_tibble(Credit)
credit = select(credit, Balance, Limit =, Income)
Summary(credit)
library(tidyverse)
library(ISLR)
credit = as_tibble(Credit)
credit = select(credit, Balance, Limit, Income)
Summary(credit)
credit = as_tibble(Credit)
credit = select(credit, Balance, Limit, Income)
summary(credit)
library(GGally)
ggscatmat(Select(credit, Balance, Limit, Income))
ggscatmat(select(credit, Balance, Limit, Income))
library(GGally)
ggscatmat(select(credit, Balance, Income, Limit))
ggscatmat(select(credit, Balance, Limit, Income))
library(GGally)
ggscatmat(select(credit, Balance, Limit, Income), color ="green" )
library(GGally)
ggscatmat(select(credit, Balance, Limit, Income), color ="green" )
library(GGally)
ggscatmat(select(credit, Balance, Limit, Income), color ='green' )
ggplot(credit, aes(x=Limit, y=Balance)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
model =lm(Balance~Limit, data=credit)
summary(model)
summary(model)
model$coefficients
model = lm(Balance~Limit+Income, data=Credit)
summary(model)
library(ggfortify)
autoplot(model)
credit = as_tibble(Credit)
credit =select(credit,Balance, Limit, Income, Rating, Age)
credit
model_1= lm(Balance~Rating , data=Credit)
summary(model_1)
model_2= lm(Balance~Age , data=Credit)
summary(model_2)
#Balance~Rating + Age
model_3= lm(Balance~Rating + Age , data=Credit)
summary(model_3)
#Balance~Rating
model_1= lm(Balance~Rating , data=Credit)
summary(model_1)
#Balance~Age
model_2= lm(Balance~Age , data=Credit)
summary(model_2)
#Balance~Rating + Age
model_3= lm(Balance~Rating + Age , data=Credit)
summary(model_3)
install.packages("gapminder")
Library(gapminder)
library(gapminder)
gapminder2007 = gapminder %>%
filter(year==2007) %>%
select(country, continent, lifeExp, gdpPercap)
gapminder2007
summary(gapminder2007$lifeExp)
ggplot(gapminder2007, aes(x=lifeExp)) +
geom_histogram(binwidth=5)
model = lm(lifeExp~1, data=gapminder2007)
model
gapminder2007 %>%
group_by(continent) %>%
summarise(count=n(),mean=mean(lifeExp))
ggplot(gapminder2007, aes(x=lifeExp)) +
geom_histogram(binwidth=5) +
facet_wrap(~continent)
gapminder2007 %>%
group_by(continent) %>%
summarise(count=n(),mean=mean(lifeExp-54.8))
model = lm(lifeExp~continent, data=gapminder2007)
model
pradeep
"pradeep
khadka"
q()
(tidyverse)
library(tidyverse)
library(tidyverse)
data = read_csv('/data/index_of_economic_freedom_2024.csv')
data = read_csv('data/index_of_economic_freedom_2024.csv')
data = read_csv('./data/index_of_economic_freedom_2024.csv')
data = read_csv("./data/index_of_economic_freedom_2024.csv")
data = read_csv("data\index_of_economic_freedom_2024.csv")
data = read_csv("data/index_of_economic_freedom_2024.csv")
data = read_csv('data/index_of_economic_freedom_2024.csv')
data = read_csv('index_of_economic_freedom_2024.csv')
data = read_csv('data/index_of_economic_freedom_2024.csv')
a = read_csv('data/index_of_economic_freedom_2024.csv')
a = read_csv('data/index_of_economic_freedom_2024.csv')
setwd("C:/Users/acer/Desktop/7144CEM_Principles_DataScience_GroupWork")
# List of required libraries
required_packages <- c("tidyverse", "GGally", "ggfortify", "cluster")
# Load all libraries
lapply(required_packages, library, character.only = TRUE)
# importing data
data = read_csv('data/index_of_economic_freedom_2024.csv')
colnames(data)
glimpse(data)
# calulating na values
colSums(is.na(data))
# remove na values
cleaned_data = na.omit(data)
# sorting overall score from high to low
cleaned_data<- cleaned_data%>%
arrange(desc(Overall_Score))
# data type
str(cleaned_data)
#visualize
ggplot(cleaned_data, aes(x = Region, y = Overall_Score, fill = Region)) +
geom_boxplot() +
labs(
title = "Distribution of Overall Score",
x = "Region",
y = "Overall_Score"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Correlation matrix
correlation_matrix <- cleaned_data %>% select_if(is.numeric) %>% cor()
correlation_matrix <- cleaned_data %>% select_if(is.numeric) %>% cor(clean_data)
cleaned_data = clean_data %>%
filter(!Country %in% c("Cuba", "North Korea"))
cleaned_data = cleaned_data %>%
filter(!Country %in% c("Cuba", "North Korea"))
cleaned_data
library(GGally)
ggpairs(cleaned_data, aes(colors(columns = 4:16, # Adjust column indices to include numeric variables
aes(color = Region),
title = "Scatter Matrix of Economic Freedom Variables by Region")))
pillar_data <- cleaned_data %>%
select(Property_Rights:Financial_Freedom)
pillar_data
# Standardize the data
pillar_data_scaled <- scale(pillar_data)
# Step 2: Perform PCA
pca_result <- prcomp(pillar_data_scaled, center = TRUE, scale. = TRUE)
pillar_data_scaled <- scale(pillar_data)
pillar_data_scaled
pca_result <- prcomp(pillar_data_scaled, center = TRUE, scale. = TRUE)
pca_result
# Step 3: Visualizations
# Screeplot
fviz_eig(pca_result, addlabels = TRUE, barfill = "steelblue", barcolor = "steelblue") +
ggtitle("Screeplot: Variance Explained by Principal Components")
library(factoextra)
# List of required libraries
required_packages <- c("tidyverse", "GGally", "ggfortify", "cluster", "factoextra")
fviz_eig(pca_result, addlabels = TRUE, barfill = "steelblue", barcolor = "steelblue") +
ggtitle("Screeplot: Variance Explained by Principal Components")
pca_result <- prcomp(pillar_data_scaled, center = TRUE, scale. = TRUE)
pca_result
# Step 3: Visualizations
# Screeplot
fviz_eig(pca_result, addlabels = TRUE, barfill = "steelblue", barcolor = "steelblue") +
ggtitle("Screeplot: Variance Explained by Principal Components")
# Step 2: Perform PCA
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
pca_result
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
pca_result
# taking variance
variance = pca_result$sdev^2 / sum(pca$sdev^2)
# taking variance
variance = pca_result$sdev^2 / sum(pca_result$sdev^2)
variance
qplot(c(), variance) +
geom_line() +
geom_point(size=4)+
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
# Screeplot
qplot(c(1:4), variance) +
geom_line() +
geom_point(size=4)+
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
# Step 2: Perform PCA
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
summary(pca_result)
pillar_data <- cleaned_data %>%
select(Property_Rights:Financial_Freedom)
glimpse(pillar_data)
# Step 2: Perform PCA
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
summary(pca_result)
# Standardize the data
pillar_data_scaled <- scale(pillar_data)
pillar_data_scaled
# Step 2: Perform PCA
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
summary(pca_result)
# taking variance
variance = pca_result$sdev^2 / sum(pca_result$sdev^2)
variance
# Screeplot
qplot(c(1:4), variance) +
geom_line() +
geom_point(size=4)+
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
# PCA biplot
library(ggfortify)
autoplot(pca_results,
label=TRUE, label.size=3, shape=FALSE,
loadings=TRUE, loadings.label=TRUE)
library(ggfortify)
autoplot(pca_result,
label=TRUE, label.size=3, shape=FALSE,
loadings=TRUE, loadings.label=TRUE)
# List of required libraries
required_packages <- c("tidyverse", "GGally", "ggfortify", "cluster", "factoextra")
# Load all libraries
lapply(required_packages, library, character.only = TRUE)
# List of required libraries
required_packages <- c("tidyverse", "GGally", "ggfortify", "cluster", "factoextra")
# Load all libraries
lapply(required_packages, library, character.only = TRUE)
install.packages("factoextra")
qplot(c(1:4), variance) +
geom_line() +
geom_point(size=4)+
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
# Step 3: Visualizations
# Screeplot
qplot(c(1:4), variance) +
geom_line() +
geom_point()+
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
# Screeplot
qplot( variance) +
geom_line() +
geom_point()+
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
# List of required libraries
required_packages <- c("tidyverse", "GGally", "ggfortify", "cluster", "factoextra")
# Load all libraries
lapply(required_packages, library, character.only = TRUE)
# importing data
data = read_csv('data/index_of_economic_freedom_2024.csv')
colnames(data)
glimpse(data)
# calulating na values
colSums(is.na(data))
# remove na values
cleaned_data = na.omit(data)
# sorting overall score from high to low
cleaned_data<- cleaned_data%>%
arrange(desc(Overall_Score))
#visualize
ggplot(cleaned_data, aes(x = Region, y = Overall_Score, fill = Region)) +
geom_boxplot() +
labs(
title = "Distribution of Overall Score",
x = "Region",
y = "Overall_Score"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# PCA Analysis
# Extract the 12 pillar variables from
pillar_data <- cleaned_data %>%
select(Property_Rights:Financial_Freedom)
glimpse(pillar_data)
# Standardize the data
pillar_data_scaled <- scale(pillar_data)
pillar_data_scaled
# Step 2: Perform PCA
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
summary(pca_result)
# taking variance
variance = pca_result$sdev^2 / sum(pca_result$sdev^2)
variance
ggplot(NULL,aes(x=1:6,y=100*variance_explained)) +
geom_col()
ggplot(NULL,aes(x=1:6,y=100*variance)) +
geom_col()
ggplot(NULL,aes(x=1:12,y=100*variance)) +
geom_col()
# Step 3: Visualizations
# Screeplot X = 1 to 12
ggplot(NULL,aes(x=1:12,y=100*variance)) +
geom_col()
ggplot(NULL,aes(x=1:12,y=100*variance)) +
geom_col()+
ggtitle("Screeplot of 12 piller variance")
# Step 3: Visualizations
# Screeplot X = 1 to 12
ggplot(NULL,aes(x=1:12,y=50*variance)) +
geom_col()+
ggtitle("Screeplot of 12 piller variance")
# Step 3: Visualizations
# Screeplot X = 1 to 12
ggplot(NULL,aes(x=1:12,y=100*variance)) +
geom_col()+
ggtitle("Screeplot of 12 piller variance")
# PCA biplot
library(ggfortify)
autoplot(pca_result,
label=TRUE, label.size=3, shape=FALSE,
loadings=TRUE, loadings.label=TRUE)
#PCA loading plot
# PCA loadings plot
loadings = as.data.frame(pca_result$rotation[,1:3])
loadings$Symbol = row.names(loadings)
loadings = gather(loadings, key='Component', value='Weight', -Symbol)
ggplot(loadings, aes(x=Symbol,y=Weight)) +
geom_bar(stat='identity') +
facet_grid(Component~.)
fviz_screeplot(pca_result, addlabels = TRUE, ylim = c(0, 50))
# PCA biplot
library(ggfortify)
autoplot(pca_result,
label=TRUE, label.size=3, shape=FALSE,
loadings=TRUE, loadings.label=TRUE)
# PCA biplot
autoplot(pca_result,
label=TRUE, label.size=3, shape=FALSE,
loadings=TRUE, loadings.label=TRUE)
get_eig(pca_result)
#PCA bi plot in factoextra
# Bi plot of individuals and variables
fviz_pca_biplot(pca_result, repel = TRUE)
fviz_pca_biplot(pca_result, repel = TRUE, geom.ind = "point")
fviz_pca_biplot(pca_result, repel = TRUE, geom.ind = "point", label ="var" )
# Bi plot of individuals and variables
fviz_pca_biplot(pca_result, repel = TRUE, geom.ind = "point", label ="var", addEllipses = TRUE )
fviz_pca_biplot(pca_result, repel = TRUE, geom.ind = "point", label ="var", addEllipses = TRUE, palette = c('gray')  )
# Bi plot of individuals and variables
fviz_pca_biplot(pca_result, repel = TRUE,
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("gra"))
# Bi plot of 12 pillar variables
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(1,2),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("gra"))
# Bi plot of 12 pillar variables
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(1,2),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
#using factoextra library to plot scree-plots
fviz_screeplot(pca_result, addlabels = TRUE, ylim = c(0, 50))
#using factoextra library to plot scree-plots
fviz_screeplot(pca_result, addlabels = TRUE, ylim = c(0, 25))
#using factoextra library to plot scree-plots
fviz_screeplot(pca_result, addlabels = TRUE, ylim = c(0, 50))
cleaned_data = cleaned_data %>%
filter(!Country %in% c("Cuba", "North Korea"))
cleaned_data
# Extract the 12 pillar variables from
pillar_data <- cleaned_data %>%
select(tax_burden:Financial_Freedom)
filter(!Country %in% c("Cuba", "North Korea"))
# importing data
data = read_csv('data/index_of_economic_freedom_2024.csv')
colnames(data)
glimpse(data)
# calulating na values
colSums(is.na(data))
# remove na values
cleaned_data = na.omit(data)
# sorting overall score from high to low
cleaned_data<- cleaned_data%>%
arrange(desc(Overall_Score))
# Extract the 12 pillar variables from
pillar_data <- cleaned_data %>%
select(tax_burden:Financial_Freedom)
# Extract the 12 pillar variables from
pillar_data <- cleaned_data %>%
select(Tax_Burden:Financial_Freedom)
glimpse(pillar_data)
