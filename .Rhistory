#
x = pull(cars, speed)
y = pull(cars, dist)
b = 4
a = mean(y) - b *mean(x)
ggplot(cars, aes(x=speed, y=dist)) +
geom_point() +
geom_abline(intercept=a , slope=b)
residuals = y - (a+b*x)
#sum of squared residuals ("leas sqaures")
SSR = sum(residuals^2)
SSR
b = sum((x-mean(x))*(y-mean(y)))/sum((x-mean(x))^2)
b
ggplot(cars, aes(x=speed, y=dist)) +
geom_point() +
geom_smooth(method=lm, se=FALSE)
model = lm(dist~speed, data = cars )
summary(model)
#Does it make sense ?
# "Eyeball"
# cofficent of determination ( R-squared )
model$residuals
model$fitted.values
(cor(cars$dist, model$residuals))^2
summary(model)
cars = tibble(cars)
cars
library(GGally)
ggpairs(cars)
install.packages("ggfortify")
install.packages(c("askpass", "backports", "BH", "bit", "bit64", "bitops", "caTools", "cli", "clipr", "config", "crayon", "curl", "digest", "dplyr", "ellipsis", "fansi", "generics", "glue", "haven", "htmltools", "htmlwidgets", "httpuv", "jsonlite", "knitr", "later", "magrittr", "markdown", "mime", "mongolite", "odbc", "openssl", "packrat", "pkgconfig", "PKI", "prettyunits", "promises", "purrr", "r2d3", "R6", "rappdirs", "Rcpp", "RCurl", "readr", "readxl", "rematch", "rJava", "RJDBC", "RJSONIO", "rlang", "rmarkdown", "rprojroot", "rsconnect", "shiny", "sourcetools", "sparklyr", "stringi", "sys", "tibble", "tidyr", "tidyselect", "tinytex", "utf8", "xfun", "xml2", "yaml"))
library("dplyr", lib.loc="C:/Users/acer/anaconda3/envs/rstudio/lib/R/library")
detach("package:dplyr", unload=TRUE)
install.packages("install.packages('GGally')")
ggplot(cars, aes(x=speed, y=dist)) +
geom_point()
library(tidyverse)
tyres
install.packages("install.packages("tidyverse")")
tyres = read_csv('tyres.csv')
#types
library(readr)
tyres = read_csv('tyres.csv')
tyres
library(readr)
tyres = read_csv('tyres.csv')
tyres
#types
library(tibble)
library(tidyverse)
library(ggplot2)
library(readr)
install.packages("tidyverse")
library(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
version()
mpg
mpg
library(tidyr)
install.packages(c("askpass", "backports", "bit", "bit64", "bitops", "caTools", "cli", "curl", "digest", "dplyr", "ellipsis", "fansi", "glue", "haven", "htmltools", "httpuv", "jsonlite", "knitr", "later", "magrittr", "mime", "mongolite", "odbc", "openssl", "PKI", "promises", "purrr", "rappdirs", "Rcpp", "RCurl", "readr", "readxl", "rJava", "RJDBC", "RJSONIO", "rlang", "sourcetools", "stringi", "sys", "tibble", "tidyr", "tidyselect", "tinytex", "utf8", "xfun", "xml2", "yaml"))
mpg
view(mpg)
ggplot(mpg,aes(x=displ,)) +geom_point()
library(tidyr)
#typ
library(tidyvers)
mpg
"pradeep Khadka"
install.packages("tidyverse")
library(tidyverse)
mpg
ggplot(mpg,aes(x=displ,)) +geom_point()
ggplot(mpg,aes(x=displ,y= hwy, size=cyl ))
+geom_point()
ggplot(mpg,aes(x=displ,y= hwy, size=cyl )) +
geom_point() +
ggtitle('fuel efficiency vs engine size')
install.packages("ISLR")
install.packages("GGally")
ggscatmat(Select(credit, Balance, Limit, Income))
install.packages("datarium")
library(tidyverse)
marketing = as_tibble(marketing)
marketing = as_tibble(marketing)
marketing
marketing
library(tidyverse)
library(datarium)
marketing = as_tibble(marketing)
marketing
ggplot(data=marketing, aes(x=youtube, y=sales)) +
geom_point()
#we want to seed the advertisement of the youtube single
ggplot(data=marketing, aes(x=youtube, y=sales)) +
geom_point()
#questions 4
x = marketing$youtube
y = marketing$sales
#Model is y= a + b*x
model = lm(y~x)
summary(model)
a = model$coefficients[1]
b = model$coefficients[2]
a
b
ggplot(marketing, aes(x=youtube, y=sales)) +
goem_point()
ggplot(marketing, aes(x=youtube, y=sales)) +
goem_point()
ggplot(marketing, aes(x=youtube, y=sales)) +
goem_point() +
goem_smooth(method=lm, se=FALSE)
ggplot(marketing, aes(x=youtube, y=sales)) +
goem_point() +
goem_smooth(method=lm, se=FALSE)
ggplot(marketing, aes(x=youtube, y=sales)) +
geom_point() +
geom_smooth(method=lm, se=FALSE)
model = lm(sales~youtube, data=marketing)
summary(model)
library(broom)
tidy(model)
fitted = argument(model)
fitted = augment(model)
fitted()
fitted = augment(model)
fitted
ggplot(fitted, aes(x=youtube, y=sales)) +
geom_point() +
geom_smooth(method=lm, se=FALSE) +
geom_segment(aes(xend=youtube, yend=.fitted), color='red', size=0.3)
library(tidyverse)
library(datarium)
marketing = as_tibble(marketing)
marketing
observed_sales = marketing$sales
observed_sales
model = lm(sales~youtube, data=marketing)
summary(model)
a
b
predicted_sales = a + b*marketing$youtube
predicted_sales
residuals_sales=observed_sales - predicted_sales
residuals_sales
ggplot(Null, aes(x=predicted_sales, y=residual_sales)) +
geom_point()
library(tidyverse)
library(datarium)
marketing = as_tibble(marketing)
marketing
observed_sales = marketing$sales
observed_sales
model = lm(sales~youtube, data=marketing)
summary(model)
a = model$coefficients[1]
b = model$coefficients[2]
a
b
predicted_sales = a + b*marketing$youtube
predicted_sales
residuals_sales=observed_sales - predicted_sales
residuals_sales
ggplot(Null, aes(x=predicted_sales, y=residual_sales)) +
geom_point()
residual_sales=observed_sales - predicted_sales
residual_sales
ggplot(Null,aes(x=predicted_sales, y=residual_sales)) +
geom_point()
ggplot(NULL,aes(x=predicted_sales, y=residual_sales)) +
geom_point()
#next way how to get the same
model = lmm(sales~youtbe, data=marketing)
model = lm(sales~youtbe, data=marketing)
model = lm(sales~youtube, data=marketing)
library(broom)
augment(model) %>%
ggplot(aes(x=.fitted, y=.resid)) +
geom_point()
ggplot(NULL,aes(x=predicted_sales, y=residual_sales)) +
geom_point()
install.packages("ggfortify")
library(ggfortify)
model = lm(sales~youtube, data=marketing)
autoplot(model)
#diagnostic plot
library(ggfortify)
model = lm(sales~youtube + facebook, data=marketing)
autoplot(model)
modelA = lm(sales~youtube, data=marketing)
summary(modelA)
modelB = lm(sales~youtube + facebook, data=marketing)
summary(modelB)
library(tidyverse)
library(ISLR)
credit = as_tibble(Credit)
credit = select(credit, Balance, Limit =, Income)
Summary(credit)
library(tidyverse)
library(ISLR)
credit = as_tibble(Credit)
credit = select(credit, Balance, Limit, Income)
Summary(credit)
credit = as_tibble(Credit)
credit = select(credit, Balance, Limit, Income)
summary(credit)
library(GGally)
ggscatmat(Select(credit, Balance, Limit, Income))
ggscatmat(select(credit, Balance, Limit, Income))
library(GGally)
ggscatmat(select(credit, Balance, Income, Limit))
ggscatmat(select(credit, Balance, Limit, Income))
library(GGally)
ggscatmat(select(credit, Balance, Limit, Income), color ="green" )
library(GGally)
ggscatmat(select(credit, Balance, Limit, Income), color ="green" )
library(GGally)
ggscatmat(select(credit, Balance, Limit, Income), color ='green' )
ggplot(credit, aes(x=Limit, y=Balance)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
model =lm(Balance~Limit, data=credit)
summary(model)
summary(model)
model$coefficients
model = lm(Balance~Limit+Income, data=Credit)
summary(model)
library(ggfortify)
autoplot(model)
credit = as_tibble(Credit)
credit =select(credit,Balance, Limit, Income, Rating, Age)
credit
model_1= lm(Balance~Rating , data=Credit)
summary(model_1)
model_2= lm(Balance~Age , data=Credit)
summary(model_2)
#Balance~Rating + Age
model_3= lm(Balance~Rating + Age , data=Credit)
summary(model_3)
#Balance~Rating
model_1= lm(Balance~Rating , data=Credit)
summary(model_1)
#Balance~Age
model_2= lm(Balance~Age , data=Credit)
summary(model_2)
#Balance~Rating + Age
model_3= lm(Balance~Rating + Age , data=Credit)
summary(model_3)
install.packages("gapminder")
Library(gapminder)
library(gapminder)
gapminder2007 = gapminder %>%
filter(year==2007) %>%
select(country, continent, lifeExp, gdpPercap)
gapminder2007
summary(gapminder2007$lifeExp)
ggplot(gapminder2007, aes(x=lifeExp)) +
geom_histogram(binwidth=5)
model = lm(lifeExp~1, data=gapminder2007)
model
gapminder2007 %>%
group_by(continent) %>%
summarise(count=n(),mean=mean(lifeExp))
ggplot(gapminder2007, aes(x=lifeExp)) +
geom_histogram(binwidth=5) +
facet_wrap(~continent)
gapminder2007 %>%
group_by(continent) %>%
summarise(count=n(),mean=mean(lifeExp-54.8))
model = lm(lifeExp~continent, data=gapminder2007)
model
pradeep
"pradeep
khadka"
q()
(tidyverse)
library(tidyverse)
library(tidyverse)
data = read_csv('/data/index_of_economic_freedom_2024.csv')
data = read_csv('data/index_of_economic_freedom_2024.csv')
data = read_csv('./data/index_of_economic_freedom_2024.csv')
data = read_csv("./data/index_of_economic_freedom_2024.csv")
data = read_csv("data\index_of_economic_freedom_2024.csv")
data = read_csv("data/index_of_economic_freedom_2024.csv")
data = read_csv('data/index_of_economic_freedom_2024.csv')
data = read_csv('index_of_economic_freedom_2024.csv')
data = read_csv('data/index_of_economic_freedom_2024.csv')
a = read_csv('data/index_of_economic_freedom_2024.csv')
a = read_csv('data/index_of_economic_freedom_2024.csv')
# List of required libraries
required_packages <- c("tidyverse", "GGally", "ggfortify", "cluster", "factoextra")
# Load all libraries
lapply(required_packages, library, character.only = TRUE)
# importing data
data = read_csv('data/index_of_economic_freedom_2024.csv')
setwd("C:/Users/acer/Desktop/7144CEM_Principles_DataScience_GroupWork")
# List of required libraries
required_packages <- c("tidyverse", "GGally", "ggfortify", "cluster", "factoextra")
# Load all libraries
lapply(required_packages, library, character.only = TRUE)
# importing data
data = read_csv('data/index_of_economic_freedom_2024.csv')
colnames(data)
glimpse(data)
# Remove NA values from givend data sets
cleaned_data = na.omit(data)
# Sorting Overall_Score from highest to lowest
cleaned_data<- cleaned_data %>%
arrange(desc(Overall_Score))
# data type
str(cleaned_data)
#Visualization of data using Region wise along with out liar
ggplot(cleaned_data, aes(x = Region, y = Overall_Score, fill = Region)) +
geom_boxplot() +
labs(
title = "Distribution of Overall Score by Region",
x = "Region",
y = "Overall_Score"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#----------> PCA Analysis of 12 pillar variables-------------------------
#==================== Part A ============================================
pillar_data <- cleaned_data %>%
select(Property_Rights:Financial_Freedom)
glimpse(pillar_data)
#Standardize the data
pillar_data_scaled <- scale(pillar_data)
pillar_data_scaled
# Step 2: Performing PCA
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
summary(pca_result)
# Calculation of each PCA variance
variance = pca_result$sdev^2 / sum(pca_result$sdev^2)
print(variance)
# Extract eigenvalues/variances
get_eig(pca_result)
#---> Step 3: Visualizations using Scree plot (X = 1 to 12 pillar) <-----
#=========================================================================
ggplot(NULL,aes(x=1:12,y=100*variance)) +
geom_col()+
ggtitle("Screeplot of 12 piller variance")
#---- PCA result visualization using Factroextra scree-plots
#========================================================================
fviz_screeplot(pca_result, addlabels = TRUE, ylim = c(0, 60))
#----> PCA bi-plot-------------------------------------------------------
#========================================================================
autoplot(pca_result,
label=TRUE, label.size=3,
shape=FALSE, loadings=TRUE,
loadings.label=TRUE
)
#-------- PCA bi-plot of 12 pillar variables using factoextra library
#========================================================================
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(1,2),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
#----->  PCA loading plot of 12 pillar variables  -----------------------
#========================================================================
loadings = as.data.frame(pca_result$rotation[,1:3])
loadings$Symbol = row.names(loadings)
loadings = gather(loadings, key='Component', value='Weight', -Symbol)
ggplot(loadings, aes(x=Symbol,y=Weight)) +
geom_bar(stat='identity') +
facet_grid(Component~.)
#----------------------> part B -----------------------------------------
#========================================================================
#filtration and removing outlier from the cleaned data sets
#----------- it is because 175 and 176 are far from the group of data
#
#cleaned_data = cleaned_data %>%
#              filter(!Country %in% c("Cuba", "North Korea"))
#cleaned_data
#========================================================
# Extract the 9 pillar variables after omitting pillar 1 variable
pillar_data <- cleaned_data %>%
select(Tax_Burden:Financial_Freedom)
glimpse(pillar_data)
#Standardize the data
pillar_data_scaled <- scale(pillar_data)
pillar_data_scaled
#----------> Step 2: Performing PCA of 9 pillar variables -----------------
#==========================================================================
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
summary(pca_result)
# Step 2: Performing PCA
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
summary(pca_result)
glimpse(pillar_data)
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
summary(pca_result)
pca_result$rotation
fviz_screeplot(pca_result, addlabels = TRUE, ylim = c(0, 60))
#========================================================================
fviz_screeplot(pca_result, addlabels = TRUE, ylim = c(0, 60))
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(1,2),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
loadings = as.data.frame(pca_result$rotation[,1:4])
loadings$Symbol = row.names(loadings)
loadings = gather(loadings, key='Component', value='Weight', -Symbol)
ggplot(loadings, aes(x=Symbol,y=Weight)) +
geom_bar(stat='identity') +
facet_grid(Component~.)
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(2,3),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
#-------- PCA bi-plot of 12 pillar variables using factoextra library
#========================================================================
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(1,2),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
#----->  PCA loading plot of 12 pillar variables  -----------------------
#========================================================================
loadings = as.data.frame(pca_result$rotation[,1:4])
loadings$Symbol = row.names(loadings)
loadings = gather(loadings, key='Component', value='Weight', -Symbol)
ggplot(loadings, aes(x=Symbol,y=Weight)) +
geom_bar(stat='identity') +
facet_grid(Component~.)
#pc2 and pc3 biplot
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(2,3),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
#========================================================================
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(1,2),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(2,3),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
#pc2 and pc3 biplot
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(2,3),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
#pc2 and pc3 biplot
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(2,3),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
#pc2 and pc3 biplot
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(2,3),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
fviz_pca_biplot(pca_result,
repel = TRUE,
axex=c(2,3),
geom.ind = "point",
label ="var",
addEllipses = TRUE,
palette = c("grey"))
# Extract the 9 pillar variables after omitting pillar 1 variable
pillar_data <- cleaned_data %>%
select(Tax_Burden:Financial_Freedom)
glimpse(pillar_data)
#Standardize the data
pillar_data_scaled <- scale(pillar_data)
pillar_data_scaled
#==========================================================================
pca_result <- prcomp(pillar_data_scaled, scale. = TRUE)
summary(pca_result)
#              filter(!Country %in% c("Cuba", "North Korea"))
#cleaned_data
#========================================================
# Extract the 9 pillar variables after omitting pillar 1 variable
pillar_data <- cleaned_data %>%
select(Tax_Burden:Financial_Freedom)
glimpse(pillar_data)
#Standardize the data
